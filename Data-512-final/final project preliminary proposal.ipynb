{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Preliminary Proposal\n",
    "\n",
    "Jiyu Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to work this kaggle project: [Jigsaw Unintended Bias in Toxicity Classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview) which expect participants to use NLP to classify toxic comments in conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to do this analysis for several reasons.\n",
    "\n",
    "First, this topic is related to our course content. It focused on classifying toxic comments. Instead of depending on crowdworkers to label millions of comments, it attempts to use machine learning to label comments which is much more efficient. Second, natural language processing (NLP) has been a popular topic in data science and I would like to use this opportunity to explore this topic. This is interesting from a human-centered perspective since it matters for us to explore better ways to classify comments on the Internet more efficiently and more effectively. I hope to learn not only some basic knowledge and skills about NLP but also some insights on the advantages and limitations of NLP in accomplishing similar tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [dataset](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/data) of this project came from the Civil Comments platform which made their comments publicly available before its shut-down. The training set contains human-annotated comments with a toxicity score. There are also identity labels provided for some comments. These identity labels represent the identities that are mentioned in the comment, which is helpful for me to identify targets of the toxic comments.\n",
    "\n",
    "This dataset is released under [CC0](https://creativecommons.org/share-your-work/public-domain/cc0/) license. It is suitable for the project, since it contains about 2 million comments and rich labels ready for analsyis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unknowns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only limitation in this project that I can think of right now is that the computation resource I have. But we have Azure credits from the department and kaggle notebooks provide free GPUs. So this should not be an issue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
